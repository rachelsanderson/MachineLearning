{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "##Load in the data\n",
    "\n",
    "vocab=np.loadtxt('out_vocab_5.txt',dtype=bytes,delimiter='\\n').astype(str)\n",
    "trainX=np.genfromtxt('out_bag_of_words_5.csv',delimiter=',', dtype=int)\n",
    "testX=np.genfromtxt('test_bag_of_words_0.csv',delimiter=',', dtype=int)\n",
    "trainY= np.loadtxt('out_classes_5.txt' , delimiter=',',skiprows=0, usecols=[0], dtype=int) \n",
    "testY= np.loadtxt('test_classes_0.txt' , delimiter=',',skiprows=0, usecols=[0], dtype=int) \n",
    "\n",
    "## Data merging for cross-validation\n",
    "\n",
    "Xarray = [trainX, testX]\n",
    "X=np.vstack(Xarray)\n",
    "Y=np.concatenate((trainY, testY), axis = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "class manageFeatures:\n",
    "    #Function for adding features coappearances \n",
    "    ## x_ij = x_i*x_j = 1 if both x_i and x_j appear and 0 otherwise \n",
    "    def addFeaturePairs(trainX,testX,vocab):\n",
    "        k=len(trainX[0,:])\n",
    "        trainXpairs=[]\n",
    "        testXpairs=[]\n",
    "        newvocab=[]\n",
    "        for i in range(k):\n",
    "            for j in range(i+1,k):\n",
    "                trainz=np.multiply(trainX[:,i],trainX[:,j])\n",
    "                trainXpairs.append(trainz)\n",
    "                testz=np.multiply(testX[:,i],testX[:,j])\n",
    "                testXpairs.append(testz)\n",
    "                newvocab.append(vocab[i]+\",\"+vocab[j])\n",
    "        trainXpairs=np.transpose(trainXpairs)\n",
    "        testXpairs=np.transpose(testXpairs)\n",
    "        return [np.concatenate((trainX, trainXpairs), axis=1),np.concatenate((testX, testXpairs),axis=1),np.concatenate((vocab, newvocab))]\n",
    "    \n",
    "    #Function for feature selection\n",
    "    def screenFeatures(trainY,trainX,testX,K,vocab):\n",
    "        h=len(trainX[0,:])\n",
    "        mut_info_scores=[skm.mutual_info_score(trainY, trainX[:,i]) for i in range(h)]\n",
    "        cutoff=sorted(mut_info_scores)[h-K]\n",
    "        count=K\n",
    "        screened_trainX=[]\n",
    "        screened_testX=[]\n",
    "        screened_vocab=[]\n",
    "        for i in range(h):\n",
    "            if mut_info_scores[i]>=cutoff and count>0:\n",
    "                screened_trainX.append(trainX[:,i])\n",
    "                screened_testX.append(testX[:,i])\n",
    "                screened_vocab.append(vocab[i])\n",
    "                count=count-1\n",
    "        return [np.transpose(screened_trainX),np.transpose(screened_testX),screened_vocab]\n",
    "    \n",
    "# Feature Selection Data\n",
    "screened_trainX,screened_testX,screened_vocab=manageFeatures.screenFeatures(trainY,trainX,testX,200,vocab)\n",
    "\n",
    "## Bigrams + Selected Feature Data\n",
    "new_trainX,new_testX,newvocab=manageFeatures.addFeaturePairs(trainX,testX,vocab)\n",
    "screened_new_trainX,screened_new_testX,screened_new_vocab=manageFeatures.screenFeatures(trainY,new_trainX,new_testX,500,newvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6a2eabada39c>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6a2eabada39c>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    temp =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "names = [\"MNB\", \"KNN\", \"Logit\", \"SVM\"\n",
    "        ]\n",
    "\n",
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(5),\n",
    "    LogisticRegression(penalty='l1'),\n",
    "    svm.SVC(kernel='linear', C=0.2, probability=True)\n",
    "    ]\n",
    "\n",
    "##Initialize dictionaries to record scoring criteria and misclassified test data\n",
    "\n",
    "score = {}  \n",
    "wrong_ids_false_negative = {}\n",
    "wrong_ids_false_positive = {} \n",
    "wrong_ids_fn_screen = {}\n",
    "wrong_ids_fp_screen = {} \n",
    "\n",
    "data = [trainX, testX]\n",
    "screened_data = [screened_trainX, screened_testX]\n",
    "screened_bigram_data = [screened_new_trainX, screened_new_testX]\n",
    "\n",
    "def finish_plots():\n",
    "\n",
    "    plt.scatter([i for i in range(len(testY))], testY, label='True Label')  \n",
    "    plt.legend()\n",
    "    plt.title('$P(c=1 | x_i)$ for test $x_i$')\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.legend()\n",
    "    plt.title('ROC AUC Curves by Classifier')\n",
    "    plt.show()\n",
    "\n",
    "def do_analysis(name, clf, data, flag):\n",
    "    # data = [trainX, testX]\n",
    "    temp = 0\n",
    "    trainX = data[0]\n",
    "    testX = data[1]\n",
    "    clf.fit(trainX, trainY)\n",
    "    predictions = clf.predict(testX)\n",
    "    probabilities = clf.predict_proba(testX)\n",
    "    false_negs = [x for x, (prediction, truth) in enumerate(zip(predictions, testY)) \n",
    "                  if prediction != truth and prediction == 0]\n",
    "    false_pos = [x for x, (prediction, truth) in enumerate(zip(predictions, testY)) \n",
    "                  if prediction != truth and prediction == 1]\n",
    "    \n",
    "    if flag == 0:\n",
    "        plot_stuff(probabilities, name)\n",
    "        wrong_ids_false_negative[name] = false_negs\n",
    "        wrong_ids_false_positive[name] = false_pos\n",
    "        scores = cross_val_score(clf, X, Y, cv=5) #Cross validation performance\n",
    "        #temp = \"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "        temp = scores.mean()\n",
    "        \n",
    "    if flag == 2:\n",
    "        wrong_ids_fp_screen[name] = false_pos\n",
    "        wrong_ids_fn_screen[name] = false_negs\n",
    "    score[name] = (skm.roc_auc_score(testY, probabilities[:,1]), clf.score(testX, testY), temp)\n",
    "    \n",
    "def plot_stuff(probs, name):\n",
    "    plt.figure(1)\n",
    "    prob_class0 = [probs[i][1] for i in range(len(probs))]\n",
    "    ids = [i for i in range(len(prob_class0))]\n",
    "    plt.scatter(ids, prob_class0, label=name)\n",
    "    plt.figure(2)\n",
    "    false_pos, true_pos, thresholds = skm.roc_curve(testY, probs[:,1])\n",
    "    plt.plot(false_pos,true_pos, label=name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for name, clf in zip(names, classifiers): \n",
    "        wrong_ids_false_positive[name] = []\n",
    "        wrong_ids_false_negative[name] = []\n",
    "        do_analysis(name, clf, data, 0)\n",
    "    finish_plots() \n",
    "    names = [\"MNB (S)\", \"KNN (S)\", \"Logit (S)\", \"SVM (S)\"]\n",
    "    for name, clf in zip(names, classifiers): \n",
    "        do_analysis(name, clf, screened_data, 1)\n",
    "        \n",
    "    names = [\"MNB (S,B)\", \"KNN(S,B)\", \"Logit (S,B)\", \"SVM (S,B)\"]    \n",
    "    for name, clf in zip(names, classifiers): \n",
    "        wrong_ids_fp_screen[name] = []\n",
    "        wrong_ids_fn_screen[name] = []\n",
    "        do_analysis(name, clf, screened_bigram_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN (S)</th>\n",
       "      <th>KNN(S,B)</th>\n",
       "      <th>Logit</th>\n",
       "      <th>Logit (S)</th>\n",
       "      <th>Logit (S,B)</th>\n",
       "      <th>MNB</th>\n",
       "      <th>MNB (S)</th>\n",
       "      <th>MNB (S,B)</th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVM (S)</th>\n",
       "      <th>SVM (S,B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    KNN  KNN (S)  KNN(S,B)  Logit  Logit (S)  Logit (S,B)   MNB  MNB (S)  \\\n",
       "0  0.75     0.77      0.80   0.89       0.86         0.88  0.86     0.84   \n",
       "1  0.66     0.70      0.76   0.82       0.79         0.81  0.77     0.76   \n",
       "2  0.69     0.00      0.00   0.78       0.00         0.00  0.77     0.00   \n",
       "\n",
       "   MNB (S,B)   SVM  SVM (S)  SVM (S,B)  \n",
       "0       0.87  0.87     0.85       0.88  \n",
       "1       0.80  0.80     0.78       0.80  \n",
       "2       0.00  0.78     0.00       0.00  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make pandas data frame to display evaluation criteria\n",
    "df = pd.DataFrame(data=score)\n",
    "df.round(2)\n",
    "#df.rename(index={0: 'ROC AUC Score'}, 1: '% Correctly Predicted', 2: 'Cross-Validation Accuracy'})\n",
    "df = df.round(2)\n",
    "# DF splits for Latex code\n",
    "# df1 = df[['KNN','Logit', 'MNB', 'SVM']]\n",
    "# df2= df[['MNB (S)','KNN (S)', 'Logit (S)', 'SVM (S)']]\n",
    "# df3 = df[['MNB (S,B)', 'KNN (S,B)', 'Logit (S,B)', 'SVM (S,B)']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(wrong_ids):\n",
    "    ##Takes in vector of wrong_ids for all classifiers and returns a dictionary of bad words with # of times they appear\n",
    "    error_words = {}\n",
    "    for key, value in wrong_ids.items():\n",
    "        temp = [testX[value[i]] for i in range(len(value))] #saving the x_i that we messed up\n",
    "                                                        # and translating x_i back into vocab\n",
    "        for x in temp:\n",
    "            bad_words = [vocab[index] for index, xi in enumerate(x) if xi != 0]\n",
    "            for word in bad_words: \n",
    "                if word not in error_words.keys():\n",
    "                    error_words[word] = 1\n",
    "                else: \n",
    "                    error_words[word] += 1\n",
    "    return error_words\n",
    "\n",
    "error_words_false_positive = evaluate(wrong_ids_false_positive)\n",
    "error_words_false_negative = evaluate(wrong_ids_false_negative)\n",
    "\n",
    "false_pos = pd.DataFrame(data=sorted(error_words_false_positive.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>film</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1\n",
       "0  good  24\n",
       "1  film  20\n",
       "2   one  12\n",
       "3  make  10\n",
       "4  look   9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_pos = pd.DataFrame(data=sorted(error_words_false_positive.items(), key=lambda x:x[1], reverse=True))\n",
    "false_neg =  pd.DataFrame(data=sorted(error_words_false_negative.items(), key=lambda x:x[1], reverse=True))\n",
    "false_pos.head() #most commonly appearing word features in false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0   film  28\n",
       "1    get  27\n",
       "2  place  27\n",
       "3   good  25\n",
       "4    one  25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_neg.head() #most commonly appearing word features in false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_fp_screen = evaluate(wrong_ids_fp_screen)\n",
    "error_fn_screen = evaluate(wrong_ids_fn_screen)\n",
    "false_pos_screen = pd.DataFrame(data=sorted(error_fp_screen.items(), key=lambda x:x[1], reverse=True))\n",
    "false_neg_screen =  pd.DataFrame(data=sorted(error_fn_screen.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB (S,B)': [0, 14, 19, 21, 22, 30, 41, 45, 49, 55, 77, 83, 202, 206, 207, 209, 218, 219, 232, 235, 250, 257, 260, 263, 266, 270, 276, 286, 290, 291, 400, 401, 405, 414, 418, 428, 430, 443, 451, 452, 473], 'KNN (S,B)': [19, 49, 85, 206, 213, 218, 219, 235, 250, 254, 260, 286, 291, 405, 418, 428, 436, 452], 'Logit (S,B)': [19, 37, 41, 45, 49, 202, 206, 207, 208, 209, 219, 232, 235, 236, 257, 260, 263, 264, 266, 270, 286, 290, 400, 401, 405, 418, 428, 430, 443, 451, 452, 473], 'SVM (S,B)': [19, 41, 45, 49, 206, 211, 218, 219, 232, 257, 260, 263, 264, 266, 270, 286, 287, 428, 430, 443, 449, 451, 473]}\n"
     ]
    }
   ],
   "source": [
    "print(wrong_ids_fp_screen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
